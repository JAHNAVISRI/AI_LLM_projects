{"id": 181, "contributed_by": "group 2", "question": "What is a common practice in placing knots when fitting splines, and how is it achieved?", "answers": ["In practice, it is common to place knots in a uniform fashion. One approach to achieve this is to specify the desired degrees of freedom for the spline. Then, the software automatically places the corresponding number of knots at uniform quantiles of the data. This uniform knot placement simplifies the modeling process."]}
{"id": 182, "contributed_by": "group 2", "question": "How does specifying degrees of freedom and uniform knot placement affect spline modeling?", "answers": ["Specifying degrees of freedom and using uniform knot placement simplifies spline modeling. It allows for a more straightforward approach to control the number of knots and their placement. By specifying degrees of freedom, you can regulate the level of flexibility, making it a practical choice for many applications."]}
{"id": 183, "contributed_by": "group 2", "question": "What is a smoothing spline?", "answers": ["Smoothing splines result from minimizing a residual sum of squares criterion subject to a smoothness penalty"]}
{"id": 184, "contributed_by": "group 2", "question": "How is the penalty term in a smoothing spline defined?", "answers": ["The penalty term in a smoothing spline is defined as the integral of the square of the second derivative of the function."]}
{"id": 185, "contributed_by": "group 2", "question": "What does the tuning parameter in a smoothing spline control?", "answers": ["The tuning parameter in a smoothing spline controls the smoothness of the smoothing spline and, in turn, its effective degrees of freedom."]}
{"id": 186, "contributed_by": "group 2", "question": "How does the smoothing spline change as the tuning parameter increases?", "answers": ["As the tuning parameter increases from 0 to a larger value, the smoothing spline becomes smoother and more constrained."]}
{"id": 187, "contributed_by": "group 2", "question": "What are the unique properties of the function that minimizes the smoothing spline penalty?", "answers": ["The function is a piecewise cubic polynomial with continuous first and second derivatives at each knot, and it is linear outside of the extreme knots."]}
{"id": 188, "contributed_by": "group 2", "question": "In the context of smoothing splines, what is the significance of effective degrees of freedom?", "answers": ["Effective degrees of freedom indicate the flexibility of the smoothing spline and how heavily the parameters are constrained or shrunk."]}
{"id": 189, "contributed_by": "group 2", "question": "How is a smoothing spline different from a natural cubic spline?", "answers": ["A smoothing spline is a shrunken version of a natural cubic spline, and the tuning parameter controls the level of shrinkage."]}
{"id": 190, "contributed_by": "group 2", "question": "What happens when the tuning parameter is set to 0 in a smoothing spline?", "answers": ["When the tuning parameter is set to 0, the smoothing spline overfits the data and is very jumpy, exactly interpolating the training observations."]}
{"id": 191, "contributed_by": "group 2", "question": "What is the loss function in the smoothing spline formulation used for?", "answers": ["The loss function encourages the smoothing spline to fit the data well, minimizing the residual sum of squares."]}
{"id": 192, "contributed_by": "group 2", "question": "How does the smoothing spline approach the linear least squares line as the tuning parameter becomes large?", "answers": ["As the tuning parameter becomes large, the smoothing spline approaches the linear least squares line because it becomes perfectly smooth and linear."]}
{"id": 193, "contributed_by": "group 2", "question": "What are Generalized Additive Models (GAMs)?", "answers": ["Generalized Additive Models (GAMs) provide a framework for extending standard linear models by allowing non-linear functions of variables while maintaining additivity. They can be used for both quantitative and qualitative responses."]}
{"id": 194, "contributed_by": "group 2", "question": "What is the significance of the additivity in GAMs?", "answers": ["Additivity in GAMs means that we calculate a separate non-linear function for each predictor variable and then combine their contributions. This allows us to examine the effect of each predictor individually while holding others constant."]}
{"id": 195, "contributed_by": "group 2", "question": "How can non-linear relationships be modeled in GAMs?", "answers": ["In GAMs, non-linear relationships are modeled by replacing linear components with non-linear functions. These functions can be constructed using various methods, such as natural splines or smoothing splines."]}
{"id": 196, "contributed_by": "group 2", "question": "What is the advantage of using GAMs?", "answers": ["GAMs allow for the modeling of non-linear relationships, potentially resulting in more accurate predictions. They are flexible and can be applied to both quantitative and qualitative responses."]}
{"id": 197, "contributed_by": "group 2", "question": "What is one limitation of GAMs?", "answers": ["One limitation of GAMs is that they are restricted to being additive models. They may not capture complex interactions between predictor variables unless additional interaction terms are included in the model."]}
{"id": 198, "contributed_by": "group 2", "question": "How can interactions be included in a GAM?", "answers": ["To include interactions in a GAM, additional terms such as Xj x Xk can be added to the model. Alternatively, low-dimensional interaction functions like fjk(Xj, Xk) can be introduced and fitted using two-dimensional smoothers or splines."]}
{"id": 199, "contributed_by": "group 2", "question": "What type of models can be used as building blocks in GAMs?", "answers": ["Various models can be used as building blocks in GAMs, including natural splines, smoothing splines, local regression, and polynomial regression. GAMs provide a flexible framework that incorporates these models as needed."]}
{"id": 200, "contributed_by": "group 2", "question": "What is the method of comparing different polynomial degrees for model selection?", "answers": ["Different polynomial degrees can be compared for model selection using hypothesis tests. One can fit multiple polynomial models of varying degrees and perform ANOVA tests to determine the simplest model that adequately explains the relationship between the response and predictors."]}
{"id": 201, "contributed_by": "group 3", "question": "What are tree-based methods used for?", "answers": ["Tree-based methods are used for regression and classification."]}
{"id": 202, "contributed_by": "group 3", "question": "What are the two main steps for predicting using a regression tree?", "answers": ["1. Divide the predictor space into distinct non-overlapping regions. 2. For each region, make a prediction using the mean response of training observations in that region."]}
{"id": 203, "contributed_by": "group 3", "question": "How are the regions created in a decision tree?", "answers": ["The regions are created by recursive binary splitting of the predictor space into high-dimensional rectangles or boxes."]}
{"id": 204, "contributed_by": "group 3", "question": "What is recursive binary splitting?", "answers": ["Recursive binary splitting is a greedy top-down approach that involves splitting the predictor space into two regions, and then repeating the process on each of the resulting regions to further split the space."]}
{"id": 205, "contributed_by": "group 3", "question": "What is used as the criterion to find the best split at each step when building a regression tree?", "answers": ["The best split is the one that leads to the greatest reduction in RSS (residual sum of squares)."]}
{"id": 206, "contributed_by": "group 3", "question": "How are classification trees different from regression trees?", "answers": ["Classification trees predict a qualitative response by using the most commonly occurring class in each region, rather than the mean response value used in regression trees."]}
{"id": 207, "contributed_by": "group 3", "question": "What are some advantages of decision trees over linear models?", "answers": ["Advantages include ease of interpretation, ability to capture complex relationships, and built-in feature selection."]}
{"id": 208, "contributed_by": "group 3", "question": "What are terminal nodes in a decision tree called?", "answers": ["Terminal nodes are also known as leaves."]}
{"id": 209, "contributed_by": "group 3", "question": "What is tree pruning and why is it useful?", "answers": ["Tree pruning involves cutting back a fully grown tree to obtain a subtree in order to avoid overfitting. It trades a little bias for a reduction in variance."]}
{"id": 210, "contributed_by": "group 3", "question": "How does cost complexity pruning work?", "answers": ["Cost complexity pruning generates a sequence of subtrees indexed by a tuning parameter that controls the tradeoff between tree size and fit to the training data."]}
{"id": 211, "contributed_by": "group 3", "question": "What is bagging?", "answers": ["Bagging involves creating multiple copies of the original training data set using bootstrap sampling, fitting a decision tree to each, and then combining the predictions."]}
{"id": 212, "contributed_by": "group 3", "question": "How does random forests improve upon bagging?", "answers": ["Random forests reduce correlation between trees by splitting each node using a subset of features chosen at random."]}
{"id": 213, "contributed_by": "group 3", "question": "What is boosting?", "answers": ["Boosting involves fitting a sequence of trees on modified versions of the data, where each successive tree is fit on the residuals from the previous tree."]}
{"id": 214, "contributed_by": "group 3", "question": "How does boosting learn slowly?", "answers": ["Each new tree in boosting is shrunk and fits the residual from the current ensemble. The learning rate hyperparameter further slows learning."]}
{"id": 215, "contributed_by": "group 3", "question": "What is Bayesian Additive Regression Trees (BART)?", "answers": ["BART is an ensemble method that fits successive trees by perturbing the previous tree to avoid overfitting. It can be seen as a Bayesian approach."]}
{"id": 216, "contributed_by": "group 3", "question": "What is the out-of-bag error in bagging?", "answers": ["The out-of-bag error provides an estimate of the test error by using predictions from those trees that did not use a given observation."]}
{"id": 217, "contributed_by": "group 3", "question": "How are qualitative predictors handled in decision trees?", "answers": ["Decision trees can split qualitative predictors without needing dummy variable encoding, by partitioning their values."]}
{"id": 218, "contributed_by": "group 3", "question": "What are the components of a decision tree?", "answers": ["The components are internal nodes, terminal nodes (leaves), branches, and regions."]}
{"id": 219, "contributed_by": "group 3", "question": "What is the deviance?", "answers": ["The deviance indicates how well the tree fits the training data. Lower deviance is better."]}
{"id": 220, "contributed_by": "group 3", "question": "What is the Gini index?", "answers": ["The Gini index is a measure of total variance across classes that is used to evaluate splits when building classification trees."]}
{"id": 221, "contributed_by": "group 3", "question": "What is entropy?", "answers": ["Entropy is a measure of node purity used as a criterion for choosing splits in classification trees."]}
{"id": 222, "contributed_by": "group 3", "question": "How are majority votes used in bagging classification trees?", "answers": ["Each tree makes a class prediction for a given observation. The overall prediction is the most common class prediction across all trees."]}
{"id": 223, "contributed_by": "group 3", "question": "What are weak learners?", "answers": ["Weak learners are simple models like single decision trees that can be combined into a more powerful ensemble."]}
{"id": 224, "contributed_by": "group 3", "question": "What is the interaction depth in boosting?", "answers": ["The interaction depth controls the complexity of boosted trees. Depth 1 corresponds to an additive model."]}
{"id": 225, "contributed_by": "group 3", "question": "What are variable importance measures?", "answers": ["Variable importance measures summarize the predictive value of each feature, such as mean Gini reduction."]}
{"id": 226, "contributed_by": "group 3", "question": "How does BART work?", "answers": ["BART fits successive trees by randomly perturbing the previous tree to avoid overfitting."]}
{"id": 227, "contributed_by": "group 3", "question": "What are the tuning parameters in boosting?", "answers": ["Important tuning parameters in boosting include the number of trees B, the learning rate, and the interaction depth."]}
{"id": 228, "contributed_by": "group 3", "question": "What is the burn-in period in BART?", "answers": ["The burn-in period refers to the initial iterations in BART that are discarded before computing the average prediction."]}
{"id": 229, "contributed_by": "group 3", "question": "How does random forests improve over bagging?", "answers": ["Random forests reduce correlation between trees by splitting nodes using random subsets of features."]}
{"id": 230, "contributed_by": "group 3", "question": "What is the difference between regression trees and linear models?", "answers": ["Regression trees partition the feature space into regions with constant prediction within each region, while linear models assume a global linear relationship."]}
{"id": 231, "contributed_by": "group 3", "question": "What is a hyperplane?", "answers": ["A hyperplane is a flat affine subspace of dimension p - 1."]}
{"id": 232, "contributed_by": "group 3", "question": "What is a maximal margin hyperplane?", "answers": ["The maximal margin hyperplane is the separating hyperplane with the largest margin."]}
{"id": 233, "contributed_by": "group 3", "question": "What is the maximal margin classifier?", "answers": ["The maximal margin classifier classifies a test observation based on which side of the maximal margin hyperplane it lies."]}
{"id": 234, "contributed_by": "group 3", "question": "What is done when classes are not linearly separable?", "answers": ["When classes are not linearly separable, the maximal margin classifier cannot be used. Instead, the support vector classifier can be used which allows some observations to violate the margin."]}
{"id": 235, "contributed_by": "group 3", "question": "What is a support vector classifier?", "answers": ["The support vector classifier is an extension of the maximal margin classifier that allows some observations to violate the margin in order to accommodate non-linearly separable classes."]}
{"id": 236, "contributed_by": "group 3", "question": "What is the role of the tuning parameter C in a support vector classifier?", "answers": ["The tuning parameter C controls the bias-variance tradeoff in a support vector classifier."]}
{"id": 237, "contributed_by": "group 3", "question": "What are support vectors?", "answers": ["Support vectors are observations that lie directly on the margin or violate the margin for their class."]}
{"id": 238, "contributed_by": "group 3", "question": "How are non-linear decision boundaries accommodated?", "answers": ["Non-linear decision boundaries can be accommodated by using kernels to expand the feature space."]}
{"id": 239, "contributed_by": "group 3", "question": "What is a support vector machine?", "answers": ["A support vector machine is an extension of the support vector classifier that uses kernels to accommodate non-linear decision boundaries."]}
{"id": 240, "contributed_by": "group 3", "question": "What is a kernel?", "answers": ["A kernel is a function that quantifies the similarity of two observations."]}
