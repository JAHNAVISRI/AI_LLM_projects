{"id": 121, "contributed_by": "group 2", "question": "Why is LOOCV considered to provide approximately unbiased estimates of the test error rate?", "answers": ["LOOCV provides approximately unbiased estimates of the test error rate because each training set in LOOCV contains n - 1 observations, which is nearly as many as the number of observations in the full data set."]}
{"id": 122, "contributed_by": "group 2", "question": "What is the primary goal of using k-fold cross-validation with k < n?", "answers": ["The primary goal of using k-fold cross-validation with k < n is to achieve a balance between bias and variance in estimating the test error rate. It provides estimates that suffer neither from excessively high bias nor from very high variance."]}
{"id": 123, "contributed_by": "group 2", "question": "How is cross-validation applied in the classification setting?", "answers": ["In the classification setting, cross-validation is applied similarly to the regression setting, but instead of using mean squared error (MSE) to quantify test error, the number of misclassified observations is used. The LOOCV error rate, k-fold CV error rate, and validation set error rates are defined based on the number of misclassified observations."]}
{"id": 124, "contributed_by": "group 2", "question": "In the classification setting, how is the LOOCV error rate defined?", "answers": ["In the classification setting, the LOOCV error rate is defined as the average number of misclassified observations. It is computed as1/n0niErri, where Erri = I(yi \u2260 ^ % yi)."]}
{"id": 125, "contributed_by": "group 2", "question": "What is the effect of using polynomial functions of predictors in logistic regression?", "answers": ["Using polynomial functions of predictors in logistic regression can result in a more flexible decision boundary. It allows for non-linear decision boundaries, which can be beneficial for capturing complex relationships in the data."]}
{"id": 126, "contributed_by": "group 2", "question": "What is the true test error rate for a standard logistic regression model in the example provided?", "answers": ["The true test error rate for a standard logistic regression model in the example provided is 0.201, which is substantially larger than the Bayes error rate of 0.133."]}
{"id": 127, "contributed_by": "group 2", "question": "How does the test error rate change when logistic regression involves cubic polynomials of the predictors?", "answers": ["The test error rate decreases when logistic regression involves cubic polynomials of the predictors. In the example provided, the test error rate decreased to 0.160 when cubic polynomials were used."]}
{"id": 128, "contributed_by": "group 2", "question": "What is the primary purpose of the bootstrap?", "answers": ["The primary purpose of the bootstrap is to quantify the uncertainty associated with an estimator or statistical learning method. It is a powerful tool for estimating variability, especially when it is difficult to obtain standard errors through other means."]}
{"id": 129, "contributed_by": "group 2", "question": "How is the bootstrap used to estimate the variability of a parameter like alpha hat (Alpha)?", "answers": ["The bootstrap approach emulates the process of obtaining new sample sets by repeatedly sampling observations from the original data set. It generates a histogram of bootstrap estimates of the parameter (e.g., Alpha), providing an estimate of the variability associated with Alpha^ without the need for additional samples. The histogram of bootstrap estimates closely resembles the idealized histogram obtained from simulated data."]}
{"id": 130, "contributed_by": "group 2", "question": "How does the bootstrap histogram of Alpha estimates compare to the idealized histogram obtained from simulated data?", "answers": ["The bootstrap histogram of Alpha estimates closely resembles the idealized histogram obtained from simulated data. The bootstrap estimate of SE(Alpha^) is very close to the estimate from simulated data, and the boxplots of estimates for Alpha also have similar spreads when using the bootstrap approach and simulated data."]}
{"id": 131, "contributed_by": "group 2", "question": "How is the validation set approach used to estimate test error rates?", "answers": ["The validation set approach is used by splitting the data into training and validation sets. The performance of different models is evaluated on the validation set, and the test error rates are estimated for each model. This helps in selecting the best-performing model."]}
{"id": 132, "contributed_by": "group 2", "question": "What does the cross_validate() function in Python produce, and which part of it provides the cross-validated test score?", "answers": ["The cross_validate() function in Python produces a dictionary with several components. The cross-validated test score, in terms of mean squared error (MSE), is one of these components. This value is estimated to be 24.23 in the example given."]}
{"id": 133, "contributed_by": "group 2", "question": "What is the purpose of using the outer() method of the np.power() function in the provided example?", "answers": ["The outer() method of the np.power() function is used to apply a given operation to pairs of elements from two arrays. It is employed to compute the cross-validation errors for polynomial fits of degrees one to five. This automation method significantly simplifies the process of calculating errors for different polynomial fits."]}
{"id": 134, "contributed_by": "group 2", "question": "What is the alternative splitting mechanism mentioned that can be used with the cross_validate() function?", "answers": ["An alternative splitting mechanism mentioned is ShuffleSplit(). "]}
{"id": 135, "contributed_by": "group 2", "question": "Why do we use alternative fitting procedures instead of least squares in simple linear models?", "answers": ["Alternative fitting procedures can yield better prediction accuracy and model interpretability."]}
{"id": 136, "contributed_by": "group 2", "question": "What is the effect of including irrelevant variables to a model?", "answers": ["Including irrelevant variables leads to unnecessary complexity in the resulting model."]}
{"id": 137, "contributed_by": "group 2", "question": "What are the three important alternative methods to using least squares to fit a linear model?", "answers": ["The three important alternative methods to using least squares are subset selection, shrinkage, and dimension reduction."]}
{"id": 138, "contributed_by": "group 2", "question": "What is subset selection?", "answers": ["Subset selection involves identifying a subset of the 'p' predictors that we believe to be related to the response. We then fit a model using least squares on the reduced set of variables."]}
{"id": 139, "contributed_by": "group 2", "question": "How does shrinkage have the effect of reducing variance?", "answers": ["Shrinkage involves fitting a model involving all 'p' predictors. However, the estimated coefficients are shrunken towards zero relative to the least squares estimates. Thus shrinkage (also known as regularization) has the effect of reducing variance."]}
{"id": 140, "contributed_by": "group 2", "question": "How is dimension reduction used as an alternative method to fit linear models?", "answers": ["Dimension reduction involves projecting the 'p' predictors into an M-dimensional subspace, where M is lesser than 'p'. This is achieved by computing M different linear combinations, or projections, of the variables. Then these M projections are used as predictors to fit a linear regression model by least squares."]}
{"id": 141, "contributed_by": "group 2", "question": "How do you perform best subset selection?", "answers": ["To perform best subset selection, we fit a separate least squares regression for each possible combination of the 'p' predictors. That is, we fit all 'p' models that contain exactly one predictor, models that contain exactly two predictors, and so forth. We then look at all of the resulting models, with the goal of identifying the one that is best."]}
{"id": 142, "contributed_by": "group 2", "question": "What is the drawback of best subset selection?", "answers": ["For computational reasons, best subset selection cannot be applied with very large 'p' predictors. It may also suffer from statistical problems when 'p' is large. The larger the search space, the higher the chance of finding models that look good on the training data, even though they might not have any predictive power on future data. Thus an enormous search space can lead to overfitting and high variance of the coefficient estimates."]}
{"id": 143, "contributed_by": "group 2", "question": "What is an alternative to best subset selection?", "answers": ["Stepwise methods such as forward and backward stepwise selection, explore a far more restricted set of models, and thus are alternatives to best subset selection."]}
{"id": 144, "contributed_by": "group 2", "question": "What is forward stepwise selection?", "answers": ["Forward stepwise selection is a computationally efficient alternative to best subset selection. It begins with a model containing no predictors, and then adds predictors to the model, one-at-a-time, until all of the predictors are in the model. In particular, at each step the variable that gives the greatest additional improvement to the fit is added to the model."]}
{"id": 145, "contributed_by": "group 2", "question": "Explain one way how backward stepwise selection is different from forward stepwise selection?", "answers": ["Unlike forward stepwise selection, backward stepwise begins with the least full squares model containing all 'p' predictors, and then iteratively removes the least useful predictor, one-at-a-time."]}
{"id": 146, "contributed_by": "group 2", "question": "What are the two approaches to selecting the best model with respect to test error?", "answers": ["The first approach is that we can indirectly estimate test error by making an adjustment to the training error to account for the bias due to overfitting. The second approach is that we can directly estimate the test error, using either a validation set approach or a cross-validation approach."]}
{"id": 147, "contributed_by": "group 2", "question": "What is Principal Component Analysis?", "answers": ["Principal Component Analysis (PCA) is a dimension reduction technique used for deriving a low-dimensional set of features from a large set of variables."]}
{"id": 148, "contributed_by": "group 2", "question": "What is the direction of the first principal component in PCA?", "answers": ["The first principal component direction of the data is that along which the observations vary the most i.e. direction along which there is the largest possible variance."]}
{"id": 149, "contributed_by": "group 2", "question": "How does the adjusted R2 differ from Cp, AIC, and BIC in model selection?", "answers": ["Adjusted R2 is a statistic used for model selection, and it differs from Cp, AIC, and BIC in that a larger value of adjusted R2 indicates a model with lower test error. The model with the largest adjusted R squared will have only correct variables and no noise variables."]}
{"id": 150, "contributed_by": "group 2", "question": "What is Bayesian Information Criterion (BIC) and what is its role in model selection?", "answers": ["Bayesian Information Criterion (BIC) is derived from a Bayesian perspective and is used in model selection. BIC places a heavier penalty on models with many variables compared to Cp and AIC, resulting in the selection of smaller models."]}
{"id": 151, "contributed_by": "group 2", "question": "How does ridge regression improve over least squares?", "answers": ["The advantage of Ridge regression is rooted in the bias-variance trade-off. As lambda increases, the flexibility of the ridge regression fit decreases, leading to decreased variance but increased bias."]}
{"id": 152, "contributed_by": "group 2", "question": "How is the one-standard-error rule used in model selection with validation sets and cross-validation?", "answers": ["The one-standard-error rule is used to select a model when multiple models have similar estimated test errors. It involves calculating the standard error of the estimated test mean squared error (MSE) for each model size. Then, the model with the lowest estimated test error within one standard error of the lowest point on the curve is selected. This rule helps choose a simpler model if several models are equally good."]}
{"id": 153, "contributed_by": "group 2", "question": "What are the advantages of using validation sets and cross-validation for model selection?", "answers": ["Using validation sets and cross-validation for model selection offers the advantage of providing a direct estimate of test error, making fewer assumptions about the true underlying model. These approaches can be applied in a wider range of model selection tasks, even when it's challenging to determine the model degrees of freedom or estimate error variance."]}
{"id": 154, "contributed_by": "group 2", "question": "Why is it recommended to standardize predictors before applying ridge regression?", "answers": ["Standardizing predictors before ridge regression is recommended to ensure that all predictors are on the same scale. Ridge regression coefficients can be influenced by the scaling of predictors, and the final fit may depend on the scaling of other predictors as well. Standardizing predictors to have a mean of zero and a standard deviation of one makes the ridge regression results independent of the scale of the predictors."]}
{"id": 155, "contributed_by": "group 2", "question": "When would ridge regression not be the suitable regression method to apply?", "answers": ["Ridge regression includes all 'p' predictors in the final model. The penalty will shrink all of the coefficients towards zero, but it will not set any of them exactly to zero (unless lambda equals to infinity). This may not be a problem for prediction accuracy, but it can create a challenge in model interpretation in settings in which the number of variables 'p' is quite large."]}
{"id": 156, "contributed_by": "group 2", "question": "How does lasso overcome the disadvantage of ridge regression?", "answers": ["The lasso uses an l1 penalty instead of l2. The lasso shrinks the coefficient estimates towards zero. However, the l1 penalty has the effect of forcing some of the coefficient estimates to be exactly equal to zero when the tuning parameter lambda is sufficiently large. Therefore, the lasso performs variable selection. As a result, models generated from the lasso are generally much easier to interpret than those produced by ridge regression."]}
{"id": 157, "contributed_by": "group 2", "question": "Which method between lasso and ridge is better?", "answers": ["In general, one might expect the lasso to perform better in a setting where a relatively small number of predictors have substantial coefficients, and the remaining predictors have coefficients that are very small or that equal zero. Ridge regression will perform better when the response is a function of many predictors, all with coefficients of roughly equal size. However, the number of predictors that is related to the response is never known a priori for real data sets. A technique such as cross-validation can be used in order to determine which approach is better on a particular data set."]}
{"id": 158, "contributed_by": "group 2", "question": "What distinguishes Partial Least Squares (PLS) from Principal Components Regression (PCR)?", "answers": ["Unlike PCR, which identifies principal components in an unsupervised manner, PLS is a supervised dimension reduction method. It considers both the predictors and the response variable to identify directions (components) that not only explain the predictors well but also have a strong relationship with the response."]}
{"id": 159, "contributed_by": "group 2", "question": "Does PCR perform feature selection?", "answers": ["No, PCR does not perform feature selection. This is because each of the M principal components used in the regression is a linear combination of all p of the original features. Therefore, while PCR often performs quite well in many practical settings, it does not result in the development of a model that relies upon a small set of the original features."]}
{"id": 160, "contributed_by": "group 2", "question": "Why has there been a shift in data collection methods over the past two decades?", "answers": ["Advances in technology have enabled the collection of data with a large number of features, leading to scenarios where the number of features is large compared to the number of observations."]}
