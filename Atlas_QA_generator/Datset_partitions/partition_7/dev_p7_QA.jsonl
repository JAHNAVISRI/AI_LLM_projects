{"id": 241, "contributed_by": "group 3", "question": "What does linear kernel do?", "answers": ["linear kernel quantifies the similarity of a pair of observations using Pearson correlation"]}
{"id": 242, "contributed_by": "group 3", "question": "What happens if we use a smaller value of the cost parameter?", "answers": ["we obtain a large number of support vectors"]}
{"id": 243, "contributed_by": "group 3", "question": "How are SVMs extended to multiple classes?", "answers": ["SVMs can be extended to multiple classes using either a one-vs-one or one-vs-all approach."]}
{"id": 244, "contributed_by": "group 3", "question": "What is the one-vs-one approach for multi-class SVMs?", "answers": ["In the one-vs-one approach, K(K-1)/2 SVMs are constructed comparing all pairs of classes."]}
{"id": 245, "contributed_by": "group 3", "question": "What is the one-vs-all approach for multi-class SVMs?", "answers": ["In the one-vs-all approach, K SVMs are constructed, each comparing one class to the remaining K-1 classes."]}
{"id": 246, "contributed_by": "group 3", "question": "How are SVMs related to logistic regression?", "answers": ["SVMs and logistic regression have similar loss functions and often yield similar results. SVMs perform better with well-separated classes while logistic regression is better in overlapping regimes."]}
{"id": 247, "contributed_by": "group 3", "question": "How can SVMs be used for regression?", "answers": ["Support vector regression extends SVMs to the regression setting by using a loss function based on the magnitude of residuals."]}
{"id": 248, "contributed_by": "group 3", "question": "Which loss function is similar to the one used in logistic regression", "answers": ["Hinge loss function is closely related to the loss function used in logistic regression"]}
{"id": 249, "contributed_by": "group 3", "question": "How are SVMs fit using inner products?", "answers": ["SVMs can be fit using only the inner products between observations, without needing the full feature vectors."]}
{"id": 250, "contributed_by": "group 3", "question": "How can the margin width be controlled in an SVM?", "answers": ["The margin width can be controlled by constraints on the coefficients on ridge term."]}
{"id": 251, "contributed_by": "group 3", "question": "What is the effect of the tuning parameter gamma in an SVM with a radial kernel?", "answers": ["In an SVM with a radial kernel, larger gamma leads to a more flexible, locally-adaptive decision boundary."]}
{"id": 252, "contributed_by": "group 3", "question": "What is the effect of using a linear kernel in an SVM?", "answers": ["Using a linear kernel in an SVM leads to a linear decision boundary."]}
{"id": 253, "contributed_by": "group 3", "question": "How are predictions made from an SVM model?", "answers": ["Predictions are made from an SVM model based on which side of the decision boundary a test observation falls on, using the sign of the decision function."]}
{"id": 254, "contributed_by": "group 3", "question": "How can confidence in predictions be assessed with SVMs?", "answers": ["Confidence in SVM predictions can be assessed based on the magnitude of the decision function output."]}
{"id": 255, "contributed_by": "group 3", "question": "What is the advantage of SVMs over logistic regression?", "answers": ["SVMs have greater robustness to individual observations far from the decision boundary compared to logistic regression."]}
{"id": 256, "contributed_by": "group 3", "question": "How can ROC curves be generated from SVMs?", "answers": ["ROC curves can be generated for SVMs by thresholding the decision function outputs at various levels."]}
{"id": 257, "contributed_by": "group 3", "question": "What causes overfitting in SVMs?", "answers": ["Overfitting in SVMs can be caused by having a small value of the cost parameter C or by using a kernel that is overly flexible."]}
{"id": 258, "contributed_by": "group 3", "question": "How can an SVM be tuned?", "answers": ["An SVM can be tuned by selecting the kernel, kernel hyperparameters like gamma, and the cost parameter C, often using cross-validation."]}
{"id": 259, "contributed_by": "group 3", "question": "What is the computational advantage of kernels?", "answers": ["Kernels allow SVMs to work in very high dimensional spaces where direct computations would be intractable."]}
{"id": 260, "contributed_by": "group 3", "question": "How does SVM relate to regularization approaches like ridge regression?", "answers": ["SVM takes a loss + penalty form similar to ridge regression, with the penalty controlling the bias-variance tradeoff."]}
{"id": 261, "contributed_by": "group 3", "question": "What is the motivation for using deep learning models?", "answers": ["The motivation is that deep learning models such as neural networks have shown impressive results on complex problems involving large datasets, such as image classification."]}
{"id": 262, "contributed_by": "group 3", "question": "What is the sigmoid activation function?", "answers": ["The sigmoid activation function is g(z) = 1/(1 + exp(-z)), which squashes the input to be between 0 and 1."]}
{"id": 263, "contributed_by": "group 3", "question": "What is backpropagation?", "answers": ["Backpropagation is the process of computing the derivatives in a neural network via the chain rule, which attributes fractions of the prediction error to each parameter."]}
{"id": 264, "contributed_by": "group 3", "question": "What is the purpose of convolution layers in a CNN?", "answers": ["Convolution layers in a CNN search for instances of small patterns in the image, in order to recognize specific features that distinguish object classes."]}
{"id": 265, "contributed_by": "group 3", "question": "What is the purpose of pooling layers in a CNN?", "answers": ["Pooling layers in a CNN provide a way to condense a large image into a smaller summary image."]}
{"id": 266, "contributed_by": "group 3", "question": "What is dropout regularization?", "answers": ["Dropout regularization randomly removes a fraction of the units in a layer when fitting the model, which prevents nodes from becoming over-specialized."]}
{"id": 267, "contributed_by": "group 3", "question": "What is the purpose of using RNNs?", "answers": ["Recurrent neural networks (RNNs) are designed to accommodate and take advantage of the sequential nature of input data such as text, time series, speech, etc."]}
{"id": 268, "contributed_by": "group 3", "question": "How are CNNs and RNNs different?", "answers": ["CNNs are designed for spatial data like images, using convolution and pooling layers, while RNNs are designed for sequential data like text, using recurrent connections."]}
{"id": 269, "contributed_by": "group 3", "question": "What is stochastic gradient descent?", "answers": ["Stochastic gradient descent (SGD) samples a small fraction of the data each time the gradient is computed, which is efficient for large datasets."]}
{"id": 270, "contributed_by": "group 3", "question": "What is the purpose of using validation data when training deep learning models?", "answers": ["Validation data is used to track model performance during training in order to detect overfitting and perform early stopping or hyperparameter tuning."]}
{"id": 271, "contributed_by": "group 3", "question": "How can overfitting be avoided when training deep neural networks?", "answers": ["Overfitting can be avoided by using regularization methods like dropout, early stopping, data augmentation, and tuning hyperparameters like batch size and number of epochs."]}
{"id": 272, "contributed_by": "group 3", "question": "What is transfer learning?", "answers": ["Transfer learning involves using a pretrained neural network on a source task as a starting point for a target task, either by freezing early layers or fine-tuning the full network."]}
{"id": 273, "contributed_by": "group 3", "question": "What is the bias-variance tradeoff?", "answers": ["The bias-variance tradeoff indicates that as model complexity increases, bias tends to decrease but variance tends to increase, so intermediate model complexity often gives optimal test error."]}
{"id": 274, "contributed_by": "group 3", "question": "What is data augmentation?", "answers": ["Data augmentation involves creating modified versions of training examples, such as randomly cropped, rotated, or flipped images, to increase diversity."]}
{"id": 275, "contributed_by": "group 3", "question": "What is the purpose of embedding layers?", "answers": ["Embedding layers represent high-dimensional sparse data like words or documents in a lower-dimensional dense vector space that preserves semantic meaning."]}
{"id": 276, "contributed_by": "group 3", "question": "How are neural networks parametrized?", "answers": ["Neural networks are parametrized by weights and biases that transform input data through multiple layers of nonlinear activation functions."]}
{"id": 277, "contributed_by": "group 3", "question": "What is multitask learning?", "answers": ["In multitask learning, a single neural network predicts multiple responses simultaneously, with all responses contributing to learning the shared hidden layers."]}
{"id": 278, "contributed_by": "group 3", "question": "What are some examples of problems where deep learning excels?", "answers": ["Some problems where deep learning excels include image classification, natural language processing, speech recognition, and time series forecasting."]}
{"id": 279, "contributed_by": "group 3", "question": "What is interpolation in machine learning?", "answers": ["Interpolation refers to fitting a flexible model that passes through all training observations, getting zero training error."]}
{"id": 280, "contributed_by": "group 3", "question": "What is double descent?", "answers": ["The double descent phenomenon refers to the observation that test error can decrease again after initially increasing when a model becomes flexible enough to interpolate the training data."]}
{"id": 281, "contributed_by": "group 3", "question": "How do neural networks achieve zero training error?", "answers": ["Neural networks can achieve zero training error through interpolation by having enough hidden units and weights to fit arbitrary functions."]}
{"id": 282, "contributed_by": "group 3", "question": "What are some limitations of relying on interpolation and double descent?", "answers": ["Limitations include sensitivity to outliers, lack of interpretability, and reliance on strong assumptions about the data distribution."]}
{"id": 283, "contributed_by": "group 3", "question": "When should simpler linear models be preferred over complex nonlinear neural networks?", "answers": ["When sample size is modest, linear models are interpretable, and the extra accuracy gains of neural networks are small, simpler linear models are often preferred."]}
{"id": 284, "contributed_by": "group 3", "question": "What are some potential downsides of neural networks compared to traditional statistical learning methods?", "answers": ["Downsides of neural networks include sensitivity to hyperparameters, lack of interpretability, computational cost, and reliance on large datasets."]}
{"id": 285, "contributed_by": "group 3", "question": "How can overparametrization affect model performance?", "answers": ["Overparametrization can help neural networks achieve zero training error through interpolation, but can also lead to overfitting without proper regularization."]}
{"id": 286, "contributed_by": "group 3", "question": "What is Bayes error rate?", "answers": ["The Bayes error rate is the lowest possible test error rate, attained when the optimal Bayesian classifier is used."]}
{"id": 287, "contributed_by": "group 3", "question": "How are neural networks initialized?", "answers": ["Neural networks are typically initialized with small random weights, which are then updated through gradient-based optimization algorithms during training."]}
{"id": 288, "contributed_by": "group 3", "question": "What is early stopping?", "answers": ["Early stopping refers to stopping optimization before convergence when performance on a validation set stops improving, as a form of regularization."]}
{"id": 289, "contributed_by": "group 3", "question": "What are convolutional filters?", "answers": ["Convolutional filters are small matrices convolved with an input image to detect the presence of certain patterns or features."]}
{"id": 290, "contributed_by": "group 3", "question": "What are the key hyperparameters when training a neural network?", "answers": ["Key hyperparameters include learning rate, batch size, number of layers and units per layer, regularization parameters, and number of training epochs."]}
{"id": 291, "contributed_by": "group 3", "question": "How does stochastic gradient descent help prevent overfitting?", "answers": ["SGD acts as a regularization method by introducing noise from minibatch sampling, allowing early stopping before convergence to a sharp minimizer."]}
{"id": 292, "contributed_by": "group 3", "question": "What types of data are not suitable for deep learning?", "answers": ["Data with few observations, little structure, low signal-to-noise ratio, or requiring interpretability may not benefit much from deep learning."]}
{"id": 293, "contributed_by": "group 3", "question": "What is vanishing gradient problem in RNNs?", "answers": ["The vanishing gradient problem refers to gradient values decreasing exponentially for long-range dependencies, impairing learning."]}
{"id": 294, "contributed_by": "group 3", "question": "How does weight sharing reduce overfitting in CNNs?", "answers": ["Weight sharing allows convolutions to detect features irrespective of location, reducing the effective model complexity."]}
{"id": 295, "contributed_by": "group 3", "question": "What types of architectures are used for sophisticated deep learning models?", "answers": ["State-of-the-art deep learning uses complex architectures like CNNs, RNNs, LSTMs, transformers, etc. combined in creative ways."]}
{"id": 296, "contributed_by": "group 3", "question": "How does the number of layers affect deep learning model performance?", "answers": ["More layers allow learning hierarchical feature representations but can lead to vanishing gradients without skip connections."]}
{"id": 297, "contributed_by": "group 3", "question": "What is distributed training?", "answers": ["Distributed training parallelizes gradient computations across multiple machines to scale up deep learning."]}
{"id": 298, "contributed_by": "group 3", "question": "What is unsupervised pretraining?", "answers": ["Unsupervised pretraining initializes a neural network through a greedy layer-wise procedure using unlabeled data."]}
{"id": 299, "contributed_by": "group 3", "question": "How do neural networks extrapolate beyond the training data distribution?", "answers": ["Neural networks often extrapolate poorly beyond the training distribution, so care is needed when deploying models."]}
{"id": 300, "contributed_by": "group 3", "question": "Why is deep learning research progressing so quickly?", "answers": ["Progress is driven by availability of data, computational power, algorithmic advances, open source code, and collaborations between academia and industry."]}
{"id": 301, "contributed_by": "group 4", "question": "What is the key to conducting inference?", "answers": ["hypothesis testing"]}
{"id": 302, "contributed_by": "group 4", "question": "What is the expected blood pressure of mice in the control group?", "answers": ["equals the expected blood pressure"]}
{"id": 303, "contributed_by": "group 4", "question": "What is the term for the false discovery rate?", "answers": [" large size and exploratory purposes"]}
{"id": 304, "contributed_by": "group 4", "question": "What is the name of the book that is written in 2020?", "answers": ["Quick Review of Hypothesis Testing"]}
{"id": 305, "contributed_by": "group 4", "question": "What is the name of the test statistic that explains the strength of evidence against the null", "answers": ["Quick Review of Hypothesis Testing "]}
{"id": 306, "contributed_by": "group 4", "question": "What is the default state of belief about the world?", "answers": ["null hypothesis alternative hypothesis"]}
{"id": 307, "contributed_by": "group 4", "question": "What is the treatment of H0 and Ha?", "answers": ["the default state of the world"]}
{"id": 308, "contributed_by": "group 4", "question": "What is the most used and abused notions in all of statistics?", "answers": ["The p-value"]}
{"id": 309, "contributed_by": "group 4", "question": "What is the default recommendation for a p-value?", "answers": ["report a two-sided p-value"]}
{"id": 310, "contributed_by": "group 4", "question": "What is the p-value a small pvalue indicates?", "answers": ["large value of the test statistic is unlikely to occur under H0"]}
{"id": 311, "contributed_by": "group 4", "question": "What is the type I error that a stockbroker can predict?", "answers": ["whether Apples stock price will increase or decrease for 10 days running"]}
{"id": 312, "contributed_by": "group 4", "question": "What is the null hypothesis that the coin is fair?", "answers": ["we just happen to have gotten ten tails in a row by chance"]}
{"id": 313, "contributed_by": "group 4", "question": "What is the main challenge of multiple testing?", "answers": ["we are bound to get some very small p-values by chance"]}
{"id": 314, "contributed_by": "group 4", "question": "What is the difference between the FWER and the FWER?", "answers": ["higher bar"]}
{"id": 315, "contributed_by": "group 4", "question": "What is the null hypothesis that the jth hedge fund manager equals zero?", "answers": ["population mean return"]}
{"id": 316, "contributed_by": "group 4", "question": "What is the Bonferroni correction?", "answers": ["sets the threshold for rejecting each hypothesis test to m"]}
{"id": 317, "contributed_by": "group 4", "question": "What is the name of the simulated data set?", "answers": ["m = 10 hypothesis tests"]}
{"id": 318, "contributed_by": "group 4", "question": "What is the name of the method that is used in the center panel?", "answers": ["Schefs method"]}
{"id": 319, "contributed_by": "group 4", "question": "What is the threshold for Schef's method?", "answers": ["S = 0.002"]}
{"id": 320, "contributed_by": "group 4", "question": "What is the value of the FWER?", "answers": ["13.3"]}
